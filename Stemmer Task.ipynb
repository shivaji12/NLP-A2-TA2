{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STEMMER TASK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "stemmerporter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevent\n",
      "govern\n",
      "forget\n",
      "boredom\n",
      "chines\n",
      "complic\n",
      "calmli\n"
     ]
    }
   ],
   "source": [
    "print( stemmerporter.stem('preventable')) # suffix -able\n",
    "print (stemmerporter.stem('government')) # suffix -ment\n",
    "print (stemmerporter.stem('forgetful')) # suffix -ful\n",
    "print (stemmerporter.stem('boredom')) # nounsuffix  -dom , Freedom, Kingdom\n",
    "print (stemmerporter.stem('Chinese')) # adj suffix -ese ,japanese, vietnamese\n",
    "print (stemmerporter.stem('Complicate')) # verb suffix -ate, dominate, irritate\n",
    "print (stemmerporter.stem(\"calmly\")) # adverb suffix -ly ,easily ,quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RegexStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "stemmerregexp=RegexpStemmer('ing')\n",
    "stemmerregexp.stem(\"Sing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kills articles with '' or '' in the subject.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerregexp=RegexpStemmer('cash|money')\n",
    "stemmerregexp.stem(\"kills articles with 'cash' or 'money' in the subject.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shiva'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerregexp=RegexpStemmer('ji')\n",
    "stemmerregexp.stem(\"Shivaji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SnowballStemmer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages # Total Languages in Snowball Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lavabl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchstemmer=SnowballStemmer('french')\n",
    "frenchstemmer.stem('lavable') # lavable (washable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dévast'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchstemmer.stem('dévastateur') #Dévast- + -ateur → dévastateur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spansih Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pesadumbr'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanishstemmer =SnowballStemmer('spanish')\n",
    "spanishstemmer.stem(\"pesadumbre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adi\n",
      "hol\n",
      "present\n"
     ]
    }
   ],
   "source": [
    "print(spanishstemmer.stem(\"Adios\"))\n",
    "print(spanishstemmer.stem(\"Hola\"))\n",
    "print(spanishstemmer.stem(\"presentar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n"
     ]
    }
   ],
   "source": [
    "lemmatizer =WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"feet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "mange\n",
      "stripe\n",
      "equation\n",
      "spinach\n",
      "quarentine\n",
      "are\n",
      "am\n",
      "goose\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"manges\"))\n",
    "print(lemmatizer.lemmatize(\"stripes\"))\n",
    "print(lemmatizer.lemmatize(\"equations\"))\n",
    "print(lemmatizer.lemmatize(\"spinaches\"))\n",
    "print(lemmatizer.lemmatize(\"quarentine\"))\n",
    "print(lemmatizer.lemmatize(\"are\"))\n",
    "print(lemmatizer.lemmatize(\"am\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stemming for Paragraph by using Porter Stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A quick brown fox jump over the lazi dog\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "example =\" A quick brown fox jumps over the lazy dog\"\n",
    "example =[stemmer.stem(token)  for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "race write introduct to paragraph frame digit & edit darl annebi  \n",
      "will be thorough, elaborate, and organized.*pleas note: thi is the s\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "example =\"\"\"\n",
    "RACES Writing Introduction to Paragraph Frames DIGITAL & EDITABLE Darl Anneby  \n",
    "will be thorough, elaborate, and organized.*PLEASE NOTE: This is the s\"\"\"\n",
    "example =[stemmer.stem(token)  for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stripe bat are hang on their feet for best\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "example = \"The striped bats are hanging on their feet for best\"\n",
    "example=[stemmer.stem(token)  for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today' task on stemmer is one of the import topic in natur languag processing, and for the stem we are use nltk tools. \n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "example = \"Today's task on stemmer is one of the important topic in natural language processing, and for the stemming we are using nltk tools. \"\n",
    "example=[stemmer.stem(token)  for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc87b7a81d43f4a5fb8eb4bff85ec1eeb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
